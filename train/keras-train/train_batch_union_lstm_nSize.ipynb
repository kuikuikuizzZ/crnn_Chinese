{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataset\n",
    "# import keys_union\n",
    "import keys_keras\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os, sys\n",
    "sys.path.insert(0, os.getcwd())\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, None, 64) 640         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, None, 64) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 16, None, 128 73856       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 8, None, 128) 0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 8, None, 256) 295168      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 8, None, 256) 590080      conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 8, None, 256) 0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 4, None, 256) 0           zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 4, None, 512) 1180160     pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, None, 512) 16          conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 4, None, 512) 2359808     batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, None, 512) 16          conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 4, None, 512) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 2, None, 512) 0           zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 1, None, 512) 1049088     pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 1, 512) 0           conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "timedistrib (TimeDistributed)   (None, None, 512)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "blstm_1 (Bidirectional)         (None, None, 512)    1574912     timedistrib[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "blstm1_dense_1 (Dense)          (None, None, 256)    131328      blstm_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "blstm_2 (Bidirectional)         (None, None, 512)    1050624     blstm1_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "blstm2_dense_2 (Dense)          (None, None, 6044)   3100572     blstm_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           blstm2_dense_2[0][0]             \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 11,406,268\n",
      "Trainable params: 11,406,252\n",
      "Non-trainable params: 16\n",
      "__________________________________________________________________________________________________\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "characters = keys_keras.alphabet_union[:]\n",
    "# characters = keys_keras.alphabet[:]\n",
    "from model import get_model_lstm\n",
    "nclass = len(characters) + 1\n",
    "trainroot = '../data/lmdb/train_competition/'\n",
    "valroot = '../data/lmdb/valid_competition/'\n",
    "# modelPath = '../pretrain-models/keras.hdf5'\n",
    "modelPath = ''\n",
    "modelPath = '/mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/competition_lstm_001676_10.h5'\n",
    "workers = 4\n",
    "imgH = 32\n",
    "imgW = 256\n",
    "keep_ratio = False\n",
    "random_sample = False\n",
    "batchSize = 32\n",
    "\n",
    "testSize = 128\n",
    "n_len = 20\n",
    "loss = 100000\n",
    "interval = 200\n",
    "LEARNING_RATE = 0.001\n",
    "Learning_decay_step = 5000\n",
    "PERCEPTION = 0.9\n",
    "EPOCH_NUMS = 100000\n",
    "MODEL_PATH = '/mnt/wuwenhui/git_ocr_project/keras_crnn/save_model'\n",
    "\n",
    "LOG_FILE = 'log.txt'\n",
    "SUMMARY_PATH = './log/'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print('Creating save model path!!')\n",
    "    os.makedirs(MODEL_PATH)\n",
    "if not os.path.exists(SUMMARY_PATH):\n",
    "    os.makedirs(SUMMARY_PATH)\n",
    "\n",
    "model, basemodel = get_model_lstm(\n",
    "    height=imgH, nclass=nclass, learning_rate=LEARNING_RATE)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=4)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = PERCEPTION\n",
    "KTF.set_session(tf.Session(config=config))\n",
    "\n",
    "# 加载预训练参数\n",
    "if os.path.exists(modelPath):\n",
    "    # basemodel.load_weights(modelPath)\n",
    "    model.load_weights(modelPath,by_name=True)\n",
    "    print('model loaded')\n",
    "\n",
    "# plot_model(basemodel, to_file='basemodel.png')\n",
    "# plot_model(model, to_file='model.png')\n",
    "\n",
    "\n",
    "def one_hot(text, length=20, characters=characters):\n",
    "    label = np.zeros(length)\n",
    "    for i, char in enumerate(text):\n",
    "        index = characters.find(char)\n",
    "        if index == -1:\n",
    "            index = characters.find(u' ')\n",
    "        if i < length:\n",
    "            label[i] = index\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nSamples:19940\n",
      "nSamples:1996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 导入数据\n",
    "if random_sample:\n",
    "    sampler = dataset.randomSequentialSampler(train_dataset, batchSize)\n",
    "else:\n",
    "    sampler = None\n",
    "train_dataset = dataset.lmdbDataset(root=trainroot, target_transform=one_hot)\n",
    "# print(len(train_dataset))\n",
    "\n",
    "test_dataset = dataset.lmdbDataset(\n",
    "    root=valroot,\n",
    "    transform=dataset.resizeNormalize((imgW, imgH)),\n",
    "    target_transform=one_hot)\n",
    "\n",
    "# 生成训练用数据\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True,\n",
    "#     sampler=sampler,\n",
    "    num_workers=2,\n",
    "    collate_fn=dataset.alignCollate(\n",
    "        imgH=imgH, imgW=imgW, keep_ratio=keep_ratio))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=testSize, \n",
    "    num_workers=0,\n",
    "    shuffle=False, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_data = iter(train_loader)\n",
    "# %time x,y = next(iter_data)\n",
    "# # print(y)\n",
    "# x = x.numpy()\n",
    "# X = x.reshape((-1, imgH, imgW, 1))\n",
    "# Y = np.array(y)\n",
    "# Length = int(imgW / 4) - 2\n",
    "# batch = X.shape[0]\n",
    "# X_train, Y_train = [\n",
    "#     X, Y, np.ones(batch) * Length,\n",
    "#     np.ones(batch) * n_len], np.ones(batch)\n",
    "# X_train[0].shape,X_train[1].shape,X_train[2].shape,X_train[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit x,y = next(iter_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!!\n",
      "32/32 [==============================] - 3s 84ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-08:48:00]--Step/Epoch/Total: [200/0/100000]\n",
      "\tTraining Loss is: [0.9299933910369873]\n",
      "\tVal Loss is: [173.42224025726318]\n",
      "\tSpeed is: [308.928635218479] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/competition_lstm_001734_10.h5\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-08:50:29]--Step/Epoch/Total: [400/0/100000]\n",
      "\tTraining Loss is: [0.3771020770072937]\n",
      "\tVal Loss is: [167.30999517440796]\n",
      "\tSpeed is: [307.7053549616277] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/competition_lstm_001673_10.h5\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-08:52:48]--Step/Epoch/Total: [600/0/100000]\n",
      "\tTraining Loss is: [3.1415038108825684]\n",
      "\tVal Loss is: [162.60876750946045]\n",
      "\tSpeed is: [316.16933658625936] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/competition_lstm_001626_10.h5\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-08:55:03]--Step/Epoch/Total: [800/1/100000]\n",
      "\tTraining Loss is: [0.5498043298721313]\n",
      "\tVal Loss is: [160.7493224143982]\n",
      "\tSpeed is: [319.73947009730233] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/competition_lstm_001607_10.h5\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-08:57:17]--Step/Epoch/Total: [1000/1/100000]\n",
      "\tTraining Loss is: [0.6042015552520752]\n",
      "\tVal Loss is: [160.72259950637817]\n",
      "\tSpeed is: [350.1047567056812] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/competition_lstm_001607_10.h5\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-08:59:30]--Step/Epoch/Total: [1200/1/100000]\n",
      "\tTraining Loss is: [0.4865022301673889]\n",
      "\tVal Loss is: [160.86897373199463]\n",
      "\tSpeed is: [345.16801855904856] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:01:43]--Step/Epoch/Total: [1400/2/100000]\n",
      "\tTraining Loss is: [0.5304938554763794]\n",
      "\tVal Loss is: [161.9208369255066]\n",
      "\tSpeed is: [336.2916946622173] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:03:56]--Step/Epoch/Total: [1600/2/100000]\n",
      "\tTraining Loss is: [0.5179216265678406]\n",
      "\tVal Loss is: [162.45509433746338]\n",
      "\tSpeed is: [348.58038999279455] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:06:09]--Step/Epoch/Total: [1800/2/100000]\n",
      "\tTraining Loss is: [0.5707206726074219]\n",
      "\tVal Loss is: [161.65673637390137]\n",
      "\tSpeed is: [243.69867570350982] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:08:21]--Step/Epoch/Total: [2000/3/100000]\n",
      "\tTraining Loss is: [0.6071819067001343]\n",
      "\tVal Loss is: [162.41128301620483]\n",
      "\tSpeed is: [287.2256180655517] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:10:35]--Step/Epoch/Total: [2200/3/100000]\n",
      "\tTraining Loss is: [1.3735685348510742]\n",
      "\tVal Loss is: [162.4158492088318]\n",
      "\tSpeed is: [330.0929017462412] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:12:46]--Step/Epoch/Total: [2400/3/100000]\n",
      "\tTraining Loss is: [1.3859728574752808]\n",
      "\tVal Loss is: [162.57578945159912]\n",
      "\tSpeed is: [330.13642130980827] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:15:00]--Step/Epoch/Total: [2600/4/100000]\n",
      "\tTraining Loss is: [0.5591938495635986]\n",
      "\tVal Loss is: [163.13340616226196]\n",
      "\tSpeed is: [346.04669889271435] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:17:20]--Step/Epoch/Total: [2800/4/100000]\n",
      "\tTraining Loss is: [1.0051157474517822]\n",
      "\tVal Loss is: [162.426411151886]\n",
      "\tSpeed is: [328.45983550006616] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:19:34]--Step/Epoch/Total: [3000/4/100000]\n",
      "\tTraining Loss is: [0.7529802322387695]\n",
      "\tVal Loss is: [162.73300790786743]\n",
      "\tSpeed is: [323.11374643803316] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:21:50]--Step/Epoch/Total: [3200/5/100000]\n",
      "\tTraining Loss is: [0.1959536373615265]\n",
      "\tVal Loss is: [162.62371397018433]\n",
      "\tSpeed is: [323.9221237680518] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:24:06]--Step/Epoch/Total: [3400/5/100000]\n",
      "\tTraining Loss is: [1.6103618144989014]\n",
      "\tVal Loss is: [164.03593015670776]\n",
      "\tSpeed is: [321.0222984877685] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:26:16]--Step/Epoch/Total: [3600/5/100000]\n",
      "\tTraining Loss is: [0.33793383836746216]\n",
      "\tVal Loss is: [162.8628249168396]\n",
      "\tSpeed is: [324.333411304837] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:28:32]--Step/Epoch/Total: [3800/6/100000]\n",
      "\tTraining Loss is: [1.2790664434432983]\n",
      "\tVal Loss is: [163.83115339279175]\n",
      "\tSpeed is: [323.92712708507185] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:30:45]--Step/Epoch/Total: [4000/6/100000]\n",
      "\tTraining Loss is: [0.16909325122833252]\n",
      "\tVal Loss is: [163.58837509155273]\n",
      "\tSpeed is: [329.97707871868977] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:32:55]--Step/Epoch/Total: [4200/6/100000]\n",
      "\tTraining Loss is: [0.6267988681793213]\n",
      "\tVal Loss is: [163.0286192893982]\n",
      "\tSpeed is: [317.1225445387275] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:35:10]--Step/Epoch/Total: [4400/7/100000]\n",
      "\tTraining Loss is: [2.6931939125061035]\n",
      "\tVal Loss is: [163.81676387786865]\n",
      "\tSpeed is: [302.9759778556071] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:37:24]--Step/Epoch/Total: [4600/7/100000]\n",
      "\tTraining Loss is: [0.6074345111846924]\n",
      "\tVal Loss is: [164.60340785980225]\n",
      "\tSpeed is: [287.671619966283] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:39:35]--Step/Epoch/Total: [4800/7/100000]\n",
      "\tTraining Loss is: [1.1712491512298584]\n",
      "\tVal Loss is: [165.20719194412231]\n",
      "\tSpeed is: [336.44734467310263] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:41:48]--Step/Epoch/Total: [5000/8/100000]\n",
      "\tTraining Loss is: [0.1982017159461975]\n",
      "\tVal Loss is: [164.98852586746216]\n",
      "\tSpeed is: [350.39226218869857] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:44:02]--Step/Epoch/Total: [5200/8/100000]\n",
      "\tTraining Loss is: [0.6307258009910583]\n",
      "\tVal Loss is: [164.61411809921265]\n",
      "\tSpeed is: [355.70496606673015] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:46:16]--Step/Epoch/Total: [5400/8/100000]\n",
      "\tTraining Loss is: [0.8506456613540649]\n",
      "\tVal Loss is: [164.91315746307373]\n",
      "\tSpeed is: [331.342630372769] Samples/Secs\n",
      "\tWriting to the file: log.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step\n",
      "Learning rate is:  0.001\n",
      "Time: [2018/10/18-09:48:31]--Step/Epoch/Total: [5600/8/100000]\n",
      "\tTraining Loss is: [0.1597611904144287]\n",
      "\tVal Loss is: [164.47718858718872]\n",
      "\tSpeed is: [323.98004662379174] Samples/Secs\n",
      "\tWriting to the file: log.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-650:\n",
      "Process Process-649:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-164a892e4322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         ], np.ones(batch)\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#         print(Y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minterval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "\n",
    "print('Start training!!')\n",
    "for i in range(EPOCH_NUMS):\n",
    "    for X, Y in train_loader:\n",
    "        start = time.time()\n",
    "        X = X.numpy()\n",
    "        X = X.reshape((-1, imgH, imgW, 1))\n",
    "#         print('Y ',Y)\n",
    "        Y = np.array(Y)\n",
    "        Length = int(imgW / 4) - 2    # 这个是使用前面的conv之后会产生的缩放？\n",
    "        batch = X.shape[0]\n",
    "        X_train, Y_train = [\n",
    "            X, Y, np.ones(batch) * Length,\n",
    "            np.ones(batch) * n_len\n",
    "        ], np.ones(batch)\n",
    "#         print(Y_train)\n",
    "        model.train_on_batch(X_train, Y_train)\n",
    "        j +=1 \n",
    "        if j % interval == 0:\n",
    "            times = time.time() - start\n",
    "            currentLoss_train = model.evaluate(X_train, Y_train)\n",
    "            crrentLoss = 0\n",
    "            for X,Y in test_loader:\n",
    "                X = X.numpy()\n",
    "                X = X.reshape((-1, imgH, imgW, 1))\n",
    "                Y = Y.numpy()\n",
    "                Y = np.array(Y)\n",
    "                batch = X.shape[0]\n",
    "                X_val, Y_val = [\n",
    "                    X, Y, np.ones(batch) * Length,\n",
    "                    np.ones(batch) * n_len\n",
    "                ], np.ones(batch)\n",
    "                crrentLoss += model.test_on_batch(X_val, Y_val)\n",
    "            print('Learning rate is: ', LEARNING_RATE)\n",
    "            now_time = time.strftime('%Y/%m/%d-%H:%M:%S',\n",
    "                                     time.localtime(time.time()))\n",
    "            print('Time: [%s]--Step/Epoch/Total: [%d/%d/%d]' % (now_time, j, i,\n",
    "                                                                EPOCH_NUMS))\n",
    "            print('\\tTraining Loss is: [{}]'.format(currentLoss_train))\n",
    "            print('\\tVal Loss is: [{}]'.format(crrentLoss))\n",
    "            print('\\tSpeed is: [{}] Samples/Secs'.format(interval / times))\n",
    "            path = MODEL_PATH + '/competition_lstm_%06d_10.h5'%(crrentLoss*10)\n",
    "            with open(LOG_FILE, mode='a') as log_file:\n",
    "                log_str = now_time + '----global_step:' + str(\n",
    "                    j) + '----loss:' + str(loss) + '\\n'\n",
    "                log_file.writelines(log_str)\n",
    "            log_file.close()\n",
    "            print('\\tWriting to the file: log.txt')\n",
    "            if crrentLoss < loss:\n",
    "                loss = crrentLoss\n",
    "                print(\"\\tSave model to disk: {}\".format(path))\n",
    "                model.save(path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = x.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
