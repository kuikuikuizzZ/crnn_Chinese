{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataset\n",
    "# import keys_union\n",
    "# import keys_keras\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os, sys\n",
    "sys.path.insert(0, os.getcwd())\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, None, 64) 640         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, None, 64) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 16, None, 128 73856       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 8, None, 128) 0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 8, None, 256) 295168      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 8, None, 256) 590080      conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 8, None, 256) 0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 4, None, 256) 0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 4, None, 512) 1180160     pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, None, 512) 16          conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 4, None, 512) 2359808     batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, None, 512) 16          conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 4, None, 512) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 2, None, 512) 0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 1, None, 512) 1049088     pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 1, 512) 0           conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "timedistrib (TimeDistributed)   (None, None, 512)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "blstm1 (Bidirectional)          (None, None, 512)    1181184     timedistrib[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "blstm1_out (Dense)              (None, None, 256)    131328      blstm1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "blstm2 (Bidirectional)          (None, None, 512)    787968      blstm1_out[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "blstm2_out_union (Dense)        (None, None, 69)     35397       blstm2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           blstm2_out_union[0][0]           \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,684,709\n",
      "Trainable params: 7,684,693\n",
      "Non-trainable params: 16\n",
      "__________________________________________________________________________________________________\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "characters = ' 0123456789ABCDEFGHIJKLMNPQRSTUVWXYZabcdefghijklmnpqrstuvwxyz-,./%￥|'\n",
    "# characters = keys_keras.alphabet[:]\n",
    "from model import get_model\n",
    "nclass = len(characters) + 1\n",
    "trainroot = '../data/lmdb/train_num_no_char_v2/'\n",
    "valroot = '../data/lmdb/valid_num_no_char_v2/'\n",
    "# modelPath = '../pretrain-models/keras.hdf5'\n",
    "modelPath = ''\n",
    "modelPath = '/mnt/wuwenhui/git_ocr_project/keras_crnn/model/my_model_keras.h5'\n",
    "workers = 4\n",
    "imgH = 32\n",
    "imgW = 256\n",
    "keep_ratio = False\n",
    "random_sample = False\n",
    "batchSize = 32\n",
    "\n",
    "testSize = 128\n",
    "n_len = 10\n",
    "loss = 100000\n",
    "interval = 200\n",
    "LEARNING_RATE = 0.005\n",
    "Learning_decay_step = 5000\n",
    "PERCEPTION = 0.9\n",
    "EPOCH_NUMS = 100000\n",
    "MODEL_PATH = '/mnt/wuwenhui/git_ocr_project/keras_crnn/save_model'\n",
    "\n",
    "LOG_FILE = 'log.txt'\n",
    "SUMMARY_PATH = './log/'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print('Creating save model path!!')\n",
    "    os.makedirs(MODEL_PATH)\n",
    "if not os.path.exists(SUMMARY_PATH):\n",
    "    os.makedirs(SUMMARY_PATH)\n",
    "\n",
    "model, basemodel = get_model(\n",
    "    height=imgH, nclass=nclass, learning_rate=LEARNING_RATE)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=4)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = PERCEPTION\n",
    "KTF.set_session(tf.Session(config=config))\n",
    "\n",
    "# 加载预训练参数\n",
    "if os.path.exists(modelPath):\n",
    "    # basemodel.load_weights(modelPath)\n",
    "    model.load_weights(modelPath,by_name=True)\n",
    "    print('model loaded')\n",
    "\n",
    "# plot_model(basemodel, to_file='basemodel.png')\n",
    "# plot_model(model, to_file='model.png')\n",
    "\n",
    "\n",
    "def one_hot(text, length=10, characters=characters):\n",
    "    label = np.zeros(length)\n",
    "    for i, char in enumerate(text):\n",
    "        index = characters.find(char)\n",
    "        if index == -1:\n",
    "            index = characters.find(u' ')\n",
    "        if i < length:\n",
    "            label[i] = index\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nSamples:13254\n",
      "nSamples:1325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 导入数据\n",
    "if random_sample:\n",
    "    sampler = dataset.randomSequentialSampler(train_dataset, batchSize)\n",
    "else:\n",
    "    sampler = None\n",
    "train_dataset = dataset.lmdbDataset(root=trainroot, target_transform=one_hot)\n",
    "# print(len(train_dataset))\n",
    "\n",
    "test_dataset = dataset.lmdbDataset(\n",
    "    root=valroot,\n",
    "    transform=dataset.resizeNormalize((imgW, imgH)),\n",
    "    target_transform=one_hot)\n",
    "\n",
    "# 生成训练用数据\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True,\n",
    "#     sampler=sampler,\n",
    "    num_workers=2,\n",
    "    collate_fn=dataset.alignCollate(\n",
    "        imgH=imgH, imgW=imgW, keep_ratio=keep_ratio))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=testSize, \n",
    "    num_workers=2,\n",
    "    shuffle=False, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_data = iter(train_loader)\n",
    "# %time x,y = next(iter_data)\n",
    "# # print(y)\n",
    "# x = x.numpy()\n",
    "# X = x.reshape((-1, imgH, imgW, 1))\n",
    "# Y = np.array(y)\n",
    "# Length = int(imgW / 4) - 2\n",
    "# batch = X.shape[0]\n",
    "# X_train, Y_train = [\n",
    "#     X, Y, np.ones(batch) * Length,\n",
    "#     np.ones(batch) * n_len], np.ones(batch)\n",
    "# X_train[0].shape,X_train[1].shape,X_train[2].shape,X_train[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit x,y = next(iter_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!!\n",
      "32/32 [==============================] - 1s 26ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:28:31]--Step/Epoch/Total: [200/0/100000]\n",
      "\tTraining Loss is: [3.1539835929870605]\n",
      "\tVal Loss is: [44.076563119888306]\n",
      "\tSpeed is: [521.3890767333625] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000440_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:29:54]--Step/Epoch/Total: [400/0/100000]\n",
      "\tTraining Loss is: [1.6718323230743408]\n",
      "\tVal Loss is: [28.042527437210083]\n",
      "\tSpeed is: [495.0865571432956] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000280_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:31:18]--Step/Epoch/Total: [600/1/100000]\n",
      "\tTraining Loss is: [1.2786567211151123]\n",
      "\tVal Loss is: [23.324016213417053]\n",
      "\tSpeed is: [509.1249851303552] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000233_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:32:41]--Step/Epoch/Total: [800/1/100000]\n",
      "\tTraining Loss is: [1.4505856037139893]\n",
      "\tVal Loss is: [20.544722318649292]\n",
      "\tSpeed is: [498.99666586361866] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000205_10.h5\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:34:05]--Step/Epoch/Total: [1000/2/100000]\n",
      "\tTraining Loss is: [0.8329486846923828]\n",
      "\tVal Loss is: [19.66263782978058]\n",
      "\tSpeed is: [508.24616283177045] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000196_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:35:27]--Step/Epoch/Total: [1200/2/100000]\n",
      "\tTraining Loss is: [0.853013277053833]\n",
      "\tVal Loss is: [17.468935430049896]\n",
      "\tSpeed is: [531.1279318979736] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000174_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:36:50]--Step/Epoch/Total: [1400/3/100000]\n",
      "\tTraining Loss is: [0.7521148324012756]\n",
      "\tVal Loss is: [15.996251821517944]\n",
      "\tSpeed is: [506.6058719264182] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000159_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:38:14]--Step/Epoch/Total: [1600/3/100000]\n",
      "\tTraining Loss is: [0.4619607627391815]\n",
      "\tVal Loss is: [15.012286096811295]\n",
      "\tSpeed is: [476.73732529281017] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000150_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:39:37]--Step/Epoch/Total: [1800/4/100000]\n",
      "\tTraining Loss is: [0.5613745450973511]\n",
      "\tVal Loss is: [14.6585433781147]\n",
      "\tSpeed is: [447.3998236770848] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000146_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:41:00]--Step/Epoch/Total: [2000/4/100000]\n",
      "\tTraining Loss is: [1.5523582696914673]\n",
      "\tVal Loss is: [13.23785588145256]\n",
      "\tSpeed is: [512.0822006950578] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000132_10.h5\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:42:23]--Step/Epoch/Total: [2200/5/100000]\n",
      "\tTraining Loss is: [0.6223772764205933]\n",
      "\tVal Loss is: [14.533947587013245]\n",
      "\tSpeed is: [509.9575552505164] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:43:46]--Step/Epoch/Total: [2400/5/100000]\n",
      "\tTraining Loss is: [1.0766524076461792]\n",
      "\tVal Loss is: [12.42209056019783]\n",
      "\tSpeed is: [516.3011439906792] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000124_10.h5\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:45:06]--Step/Epoch/Total: [2600/6/100000]\n",
      "\tTraining Loss is: [0.2631191611289978]\n",
      "\tVal Loss is: [12.355918258428574]\n",
      "\tSpeed is: [516.7811084237594] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000123_10.h5\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Learning rate is:  0.005\n",
      "Time: [2018/10/23-03:46:29]--Step/Epoch/Total: [2800/6/100000]\n",
      "\tTraining Loss is: [0.9748981595039368]\n",
      "\tVal Loss is: [11.396826922893524]\n",
      "\tSpeed is: [507.5631594424229] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /mnt/wuwenhui/git_ocr_project/keras_crnn/save_model/num_char_000113_10.h5\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "\n",
    "print('Start training!!')\n",
    "for i in range(EPOCH_NUMS):\n",
    "    for X, Y in train_loader:\n",
    "        start = time.time()\n",
    "        X = X.numpy()\n",
    "        X = X.reshape((-1, imgH, imgW, 1))\n",
    "#         print('Y ',Y)\n",
    "        Y = np.array(Y)\n",
    "        Length = int(imgW / 4) - 2\n",
    "        batch = X.shape[0]\n",
    "        X_train, Y_train = [\n",
    "            X, Y, np.ones(batch) * Length,\n",
    "            np.ones(batch) * n_len\n",
    "        ], np.ones(batch)\n",
    "#         print(Y_train)\n",
    "        model.train_on_batch(X_train, Y_train)\n",
    "        j +=1 \n",
    "        if j % interval == 0:\n",
    "            times = time.time() - start\n",
    "            currentLoss_train = model.evaluate(X_train, Y_train)\n",
    "            crrentLoss = 0\n",
    "            for X,Y in test_loader:\n",
    "                X = X.numpy()\n",
    "                X = X.reshape((-1, imgH, imgW, 1))\n",
    "                Y = Y.numpy()\n",
    "                Y = np.array(Y)\n",
    "                batch = X.shape[0]\n",
    "                X_val, Y_val = [\n",
    "                    X, Y, np.ones(batch) * Length,\n",
    "                    np.ones(batch) * n_len\n",
    "                ], np.ones(batch)\n",
    "                crrentLoss += model.test_on_batch(X_val, Y_val)\n",
    "            print('Learning rate is: ', LEARNING_RATE)\n",
    "            now_time = time.strftime('%Y/%m/%d-%H:%M:%S',\n",
    "                                     time.localtime(time.time()))\n",
    "            print('Time: [%s]--Step/Epoch/Total: [%d/%d/%d]' % (now_time, j, i,\n",
    "                                                                EPOCH_NUMS))\n",
    "            print('\\tTraining Loss is: [{}]'.format(currentLoss_train))\n",
    "            print('\\tVal Loss is: [{}]'.format(crrentLoss))\n",
    "            print('\\tSpeed is: [{}] Samples/Secs'.format(interval / times))\n",
    "            path = MODEL_PATH + '/num_char_%06d_10.h5'%(crrentLoss*10)\n",
    "            with open(LOG_FILE, mode='a') as log_file:\n",
    "                log_str = now_time + '----global_step:' + str(\n",
    "                    j) + '----loss:' + str(loss) + '\\n'\n",
    "                log_file.writelines(log_str)\n",
    "            log_file.close()\n",
    "            print('\\tWriting to the file: log.txt')\n",
    "            if crrentLoss < loss:\n",
    "                loss = crrentLoss\n",
    "                print(\"\\tSave model to disk: {}\".format(path))\n",
    "                model.save(path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
